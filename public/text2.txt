AI가 탑재된 클라우드 솔루션

​

​

데이터 사이언티스트로서 위기감과 고민이 많아지는 요즘이다.

젊다못해 어리다고도 할 수 있는 20대임에도 AI의 발전속도와 이에 따른 산업의 니즈 변화는 도저히 못따라갈 수준이다

​

​

​

단순히 ChatGPT로 대표되는 생성형 AI의 발전뿐만 아니라 

분석이라는 업무도 가면 갈수록 입지가 좁아지게 되는데, 

이를 체감하게 해준 것은 GCP와 AWS를 실무에서 접해본 후이다.

​

​

물론 이 둘은 출시된지 몇 년이 지난 서비스지만 ,

최근에 부가 서비스로 구글은 BQML, AutoML 등 머신러닝/딥러닝 서비스를 추가하였고

AWS는 이미 가지고 있던 SageMaker라는 AI 예측분석 툴을 더욱 고도화해가며 강력한 분석기능을 자랑하고 있다.

​

​


출처 : Automate model retraining with Amazon SageMaker Pipelines when drift is detected | AWS Machine Learning Blog

​

​

이러한 클라우드 기반 ML 솔루션들의 장점이자 비전은 "AI의 대중화"이다.

그만큼 누구나 최소한의 지식만으로 데이터를 다루고 분석하고  결과를 해석할 수 있게끔 한다는 것인데,

클라우드 사용법과 기초SQL만 알면 정말이지 누구나 AI를 활용하여 분석이 가능하다.

​

​

그래서 이제 DA(DS), AI 개발자는 갈수록 필요가 없어질 것이다. 

현업의 도메인 경험이 풍부한 사람이 위 클라우드 솔루션들을 배우는 것이

데이터 업종의 사람이 도메인 지식을 습득하고 이를 분석에 활용하는 것보다 몇 배는 쉽기 때문이다.

​

​

​

​

너무 오바인 것 같다면 아래 구글의 BQML(BigQuery ML)의 사용 예시를 보자

​


​

​

물론 매우 간단한 데이터와 모델링이긴 하지만 20줄만에 모델링이 끝난다.

짧은 코드로 가능한 것도 놀랍지만, SQL로 전처리와 모델링까지 가능하도록 한 것이 인상적이다

​

제공하는 모델의 종류와 수준은 어떨까?

수십가지의 수치예측/이상탐지/이미지 객체인식/음성분석, 심지어 LLM까지

자체 특허만 10개 이상의 무려 구글이 만든 머신러닝과 딥러닝 모델들이 제공되고 있다.

​

​

구글의 AutoML은 더 가관이다.

그냥 데이터만 넣어주면 알아서 파생변수도 만들어보고, 여러가지 ML/DL 모델을 돌려보고, 파라미터 조정도 하고 , 앙상블하여 최적의 결과를 내주는데

이는 평균적으로 일반 분석가가 6개월 이상 분석하는 과정과 결과의 수준이 비슷하며, AutoML은 6시간 정도면 끝난다.


​

​

​

처음 이런 사실을 접하고, 그리고 실제로 사용도 해보니 모델 개발에 관심이 많은 분석가인 나에겐 

이제 막 목적지를 정하고 달리기 시작한 와중에  이미 그곳을 찍고 다른 곳을 향하는 1등을 본 느낌이었다. 

​

​

그럼에도 불구하고, 다행히도

ML 솔루션까지 더해서 솔루션을 구매하는 것은 아직 비용적으로 많이 비싸기 때문에 기업 입장에선 도입하기 쉽지 않고,

분석가를 비롯한 데이터 직무들이 활약할 수 있는 분야는 아직 있기 때문에 이에 집중하는 방식으로 미래를 준비해야한다.

​

​

​

모델링보다 중요한 것

​

​

당연히 클라우드기반 AI솔루션을 그대로 쓰기엔

기업 특유의 도메인 상황과 데이터 특성, 예외상황 등 고려해야할 사항이 무척이나 많고

현재 수준으로는 그 어떤 모델도 이러한 것들을 모두 극복할만큼 뛰어나지는 않다.

​

​

그렇기에 "데이터 사이언스"의 본질이 더 중요해진다.

데이터 자체의 분포와 수집기의 특성, 도메인 지식과 결합된 이해로 

raw 데이터 자체를 무분별하게 모델에 집어넣을 것이 아니라 

그 데이터에 맞게 전처리를 해주고, 파생변수를 만들어 주어 가공을 해줄 필요성이 있다.

​

​

ML/DL이 널리 알려지기 시작한 때부터 앞으로도 변치 않을 데이터사이언스의 제1법칙은

"garbage IN, garbage OUT" , 입력 데이터의 품질이 절대적으로 중요하다는 것이다.

​


출처 : Data Preprocessing in Data Mining - GeeksforGeeks

​

모델링을 많이 해보고 각종 대회에 나가보거나 현업을 하고 있다면 알겠지만

사실 성능에 있어서 기초적인 통계모델이나 최근논문에 나올만한 딥러닝모델이나 크게 차이가 없다.

중요한 건 데이터를 잘 전처리해서 정말 핵심적인 변수들을 잘 가공해놓는 것이고,

이를 위해선  도메인 지식과 경험을 결합한 데이터 사이언스 스킬이 필수적인 조건이 된다.

​

​

혹시나하여 언급하자면 

이 글은 더 이상 분석과 모델링을 할 필요가 없다는 뜻이 아니라 

분석과 모델링이 갈수록 쉬워지고 누구나 할 수 있도록 진화하고 있으니 이를 메인으로 붙잡고 있지 말자는 것이다.

​

​

결론은 "모델링에 들였던 시간과 노력을 최소한으로 하고, 절약한 만큼을 데이터이해와 전처리에 더 투자하는 것" 이다. 

​

​

​

주인공이 된 데이터 엔지니어

​

​

이러한 솔루션을 외부에서 구입하든 아니면 자체적으로 구축을 했다고 하고, 

데이터를 잘 이해하고 처리 및 분석해줄 분석가도 수두룩하게 있다고 하자.

완벽한 파이프라인이 구축되어 있다. 

​

그럼 이제 어떻게 물(데이터)을 흘려 보낼 것인가? 

​


​

​

수집기에서 클라우드의 데이터저장소로 L0 데이터를 연동하고 

거기서부터 파생되는 L1, L2 데이터를 관리하고 이를 분석계, 서비스계 까지 

계속 연동해주고 관리하는 역할의 중요성이 더없이 커졌다.

​

​

대부분의 과제들이 데이터를 활용함에 따라

이제는 데이터 엔지니어가 없다면 그 첫 시작조차도 할 수 없게 되었다.

물론 클라우드 솔루션이 데이터 연동과 모니터링 기능도 손쉽게 제공하긴 하지만,

사내 보안 방화벽과 거버넌스가 있는이상 이 모든 작업은 데이터 엔지니어가 해줘야 하는 것이고

이렇다보니 클라우드와 플랫폼의 소유권와 관리 역할도 엔지니어에게 가게 된다.

​

​

데이터 엔지니어는 지금까지는 아직 그 중요성을 잘 인식하는 사람도 별로 없고 실력자도 적었지만,

이젠 기업의 모든 데이터 과제에 참여하고 필수적인 역할을 수행하며 AI산업의 주인공으로 올라서게 되었다.

​

​

엔지니어가 각광받는 건 남의 일이라 생각될테지만

분석가 또한 가능하다면 데이터 엔지니어링 영역을 커버하여 기본적인 연동과 DB관리를 익혀둔다면

흔히 말하는 "모델링 말고는 아무것도 못하는 바보" 신세를 면하고 좀더 주도적인 역할을 할 수 있을 것이다.

​

​

이제는 ServiceOps의 시대

​

​

​

언어의 유행이 너무 빠르게 지나간다고 느끼는 게

20~21년에는 개발자 유행과 더불어 개발과 배포 및 운영이 긴밀하게 연결된 DevOps가 유행하고

22년~23년에는 AI개발의 수요 증가와 함께 Closed Loop 학습이 가능한 AIOps라는 단어가 새로 나왔는데

24년 올해는 이 AIOps와 함께 ServiceOps​가 키워드가 되고 있다.

​

​

ServiceOps는 

유저가 AI를 체험 및 사용할 수 있는 수준인 서비스 개발을 최우선 목표로 하여 빠르게 배포, 업데이트 및 운영하는 업무구조를 의미한다.

DevOps와는 AI가 서비스의 핵심이라는 점에서 다르고, AIOps는 AI의 개발과 학습에 포커스를 둔 반면 serviceops는 AI의 활용과 배포에 중점을 뒀다는 점에서 차이가 있다.

​

​

뜬금없이 개발이나 분석과 동떨어져 보이는 Service 라는 단어가 나온 이유 또한 클라우드 솔루션의 발전에 있는데,  

이젠 DevOps와 AIOps를 이미 그 자체로 가능하게끔 되었기 때문이다.

거기에 이 시스템 상에선 AI모델의 파리미터 조정이나 학습 설계 등 모델링에 필요한 시간과 노력이 많이 줄어들기 때문에 

빠르게 이것을 서비스화하여 고객들에게 제공하는 것이 더 중요해졌다.

​

​

AI 개발이 양산형으로 빠르고 다량으로 가능해지면서

이제는 이를 활용한 서비스 상품을 기획하는 능력, 즉 창의성이 중요해졌고

동시에 기술적으로 이를 패키징할 프론트엔드 개발 또한 다시 주목받고 있다.

(기술 측면보다는 얼마나 편하고 예쁘게 UI를 구성하냐는 관점에서)

​

​

결국 고객에게 직접으로 제공되는 서비스 상품이든 아니면 ERP 시스템이든

중간 과정인 AI개발과 분석은 매우 쉬워졌고, 데이터만 준비되어 있다면

이젠 이것을 어떻게 사용할 것인가, 그리고 얼마나 user-friendly하게 개발할 것인가가 AI산업의 key가 될 것이라 전망해 본다.

​

​

그리고 데이터 사이언티스트 또한 거시적인 비즈니스 관점에서

산업과 소비자를 이해하고 그 니즈를 만족시켜줄 서비스를 어떻게 AI를 활용하여 해결할 것인가 

를 고민하는 방향으로 업무가 변화해야 한다고 생각한다.